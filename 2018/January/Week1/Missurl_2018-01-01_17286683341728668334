{
    "threat_intelligence": {
        "url": "https://cybersecurity.springeropen.com/articles/10.1186/s42400-023-00180-x",
        "timestamp": "2018-01-01 00:00:00",
        "original_content": "In this section, we show the experimental results of the above-proposed graph generation method and detection methods \nAparecium\n. First, we demonstrate the superiority of the graph construction method by comparing the horizontal and vertical methods. Second, we conduct comparative experiments on detection schemes with multiple model comparisons. Finally, deploy \nAparecium\n to Ethereum to discover new scam-relatively behaviors. The dataset is now open to \nhttps://drive.google.com/drive/folders/1Ap4sMsmg5pZZi-Y3_YWxhfl8ZhWzbcRn?usp=sharing\n.\nGraph generation method evaluation\nIn this subsection, we conduct experiments on the Ethereum transaction subgraph obtained by the method described in Section The Aparecium Model. We use four popular feature extraction methods combined with the random forest classifier to detect scam behavior on Ethereum. At the same time, we compared four other popular Ethereum graph generation methods and found that the graph generation method proposed in this paper has stability and universality.\nBaseline Methods\n For the node embedding method, we compared two kinds of graph representation learning methods and two kinds of graph deep learning methods to test the stability in the horizontal method, namely DeepWalk (Perozzi et\u00a0al. \n2014\n), node2vec (Grover and Leskovec \n2016\n), GCN (Kipf and Welling \n2016\n) and GraphSage (Hamilton et\u00a0al. \n2017\n). At present, the popular Ethereum graph generation methods can be divided into random time period-based, random address-based, and policy-based selective address graph generation methods. We compare these 3 types of methods to test the dominance of our methods over longitudinal methods.\nMetrics\n We consider three evaluation metrics, namely precision, recall and F1-score. The three metrics are defined as follows:\nF\n1\n\u2212\ns\nc\no\nr\ne\n=\n2\n\u2217\nP\nr\ne\nc\ni\ns\ni\no\nn\n\u2217\nR\ne\nc\na\nl\nl\nP\nr\ne\nc\ni\ns\ni\no\nn\n+\nR\ne\nc\na\nl\nl\n\n                    (17)\n                \nwhere \nTP\n is true positive, \nFP\n is false positive and \nFN\n is false negative. The specific results are shown in Table \n2\n.\nMain Results\n (1) Compared with graph representation learning, the graph deep learning model has a stronger expressive ability, so the final result is slightly better than the two graph representation learning methods. But the results in the horizontal method are not much different so it proves the stability.\n(2) For the graph generation method based on the random time period, all data from 2018.1 to 2020.5 were selected in the experiment. After simple noise processing, the proportion of abnormal nodes was only 0.059%. For the method based on random address, the experiment start from the 1165 source nodes including 1157 malicious nodes. 2,973,382 nodes were randomly crawled, and the proportion of abnormal nodes was only 0.038%. Since the downstream task is the anomaly detection task, these two types of methods do not perform graph pruning and imbalance processing at the construction level, so the final detection performance is not ideal.\n(3) For policy-based selective addresses, two strategies are compared in the experiment. The first one contains 1259 phishing addresses, and 1259 normal addresses and first-order neighbor addresses are randomly selected, with a total of about 60,000 nodes and abnormal nodes. It accounts for 2.098%; the second type contains 1,000 phishing addresses, and randomly selects 1,000 normal addresses, a total of about 80,000 nodes, and abnormal nodes account for 1.250%. It can be seen that when abnormal nodes proportion increase, the final detection performance will also be further improved.\n(4) Our method belongs to a strategy-based selective address graph generation method, with abnormal nodes accounting for 3.793% that the final detection performance has certain advantages. Under such a subgraph, the behavior and semantics of malicious nodes can be better learned. Also, the analysis and detection of malicious behaviors on Ethereum can be focused on.\nTable 2 Performance comparison in different models and graph generation methods\nFeature extraction method and classification model evaluation\nBaseline Methods\n This paper proposes an embedding algorithm suitable for the detection of scam behavior in Ethereum. In order to reflect its advantages, we use other network embedding algorithms for comparison. Among them, DeepWalk and Node2vec are node embedding methods based on the walking strategy, in which DeepWalk is a random walk, and context learning is performed through co-occurred nodes. Node2vec is a biased walk, and node context learning is performed through the offset of local and global. Trans2vec is a biased walk for Ethereum\u2019s phishing behavior. GraphSage and GCN are node embedding algorithms for deep neural networks and learn node context through the aggregation of neighbor features. T-EDGE (Lin et\u00a0al. \n2020b\n), I\n2\nBGNN (Shen et\u00a0al. \n2021\n) and MCGC (Zhang et\u00a0al. \n2021\n) are detectors which dedicate to the Ethereum abnormal behavior detection.\nBesides, we also compared the popular classification models which will impact the detection performance. We compared with logistic regression, isolate forest, support vector machine (SVM) and naive bayes under our feature extraction method.\nImplementation Details\n To implement the above embedding algorithm, we use the following parameters. For the walk-based embedding algorithm, we set the following parameters: embedding dimension \nd\n=\n32\n, length of walk \nl\n=\n7\n, number of walks per node \nr\n=\n20\n, context size \nk\n=\n9\n. For node2vec, set \np\n=\n0.75\n, \nq\n=\n2\n; for Trans2vec (Wu et\u00a0al. \n2020\n), set search bias parameter \n\u03b1\n=\n0.5\n; for our proposed feature extraction part, set network structure bias parameter \n\u03b1\n=\n0.9\n, pure semantic bias parameter \n\u03b2\n=\n0.5\n, time mixed bias parameter \n\u03b3\n=\n0.2\n. For the neural network algorithm GraphSage and GCN, 2 layers of convolutional layers are set, the first layer uses 512 neurons, the second layer uses 256 neurons, the embedding size is 256 dimensions, the learning rate is 0.01, and the epoch is 40. For the detectors algorithm, we use the framework and optimal parameters detailed in their papers respectively.\nThe effects of embedding\n To highlight the significance of risk identification features, we conducted an experiment where we solely utilized these features for sampling without embedding. This approach was taken considering the bias inherent in our method. The experimental results, presented in Table \n3\n, demonstrate the outcome of this analysis.\nTable 3 Results of nonembedding algorithms of single feature\nThe effects of the risk identification features\n It can be seen from Table \n3\n that if the embedding algorithm is not used, the final detection effect of the scam behavior is not satisfactory. But from the results, it can be seen that the detection results are the best when all features are used, and the results of combined features are also significantly better than single features. The results show that not using graph structure information has a greater impact on the detection effect.\nTable 4 Results of detection with different embedding methods\nMain Results\n Table \n4\n shows the results after using the graph structure information, that is, the results after using the embedding algorithm. Table \n5\n shows the results about the classification models under our embedding algorithm.\nTable 5 Results of detection with different classification models\n\n\n\n\n(1)\n\n\nThe results show that our proposed algorithm is significantly higher than other methods in terms of F1-score and recall, but precision is slightly lower than GCN.\n\n\n\n\n\n\n(2)\n\n\nIn addition, it can be seen that the results of network structure bias, pure semantic bias, and time mixed bias sampling are all higher than random walk sampling DeepWalk, which proves that the risk identification points we extracted can effectively describe the scam behavior in the Ethereum transaction network.\n\n\n\n\n\n\n(3)\n\n\nAt the same time, the results in Tables \n3\n and \n4\n also show that the joint action of risk identification points and structural information can achieve the best scam behavior detection effect.\n\n\n\n\n\n\n(4)\n\n\nBesides, the results in Table \n5\n shows the performance of random forest is better than the other popular classifier. Thus, we select random forest for \nAparecium\n.\n\n\n\n\nParameter analysis\nFor our proposed detection algorithm, there are many hyperparameters that will affect the final test result. Here we only show the changing trend of the hyperparameters that have a greater impact on the final scam behavior detection result. In the experiment, the control variable method is adopted, that is, when a parameter is changed in the experiment, the other parameters keep the default value.\nBias Parameter\n Firstly, as shown in Fig.\u00a0\n4\n, we explored the three offset parameters \n\u03b1\n, \n\u03b2\n, \n\u03b3\n, and set each parameter from 0.1 to 0.9. For \n\u03b1\n, the trend of the three indicators is relatively stable, and the peak appears when \n\u03b1\n=\n0.9\n. This shows that the importance of the two identification points is not much difference between the in-out ratio and the maliciousness, and the in-out ratio is slightly more important. For \n\u03b2\n, the trend of the three indicators is relatively flat, reaching a peak at 0.5. This shows that the transaction amount and the number of transactions are equally important, and both are indispensable. For \n\u03b3\n, the indicators fluctuated slightly, reaching their maximum value at 0.2. This shows that the naughty attribute we defined has a more important role than the timestamp.\nFig. 4\nResults of (\na\n)\u2013(\nc\n) bias parameters analysis\nOther Hyperparameters\n We also experimented with various hyperparameters of the embedding method, as shown in Fig.\u00a0\n5\n. With the increase of embedding dimension \nd\n, the overall indicators show an upward trend, reaching a peak when \nd\n=\n32\n, and decreasing slightly when \nd\n=\n64\n. The reason may be that although the increase of dimension can carry more information, the original feature can basically describe the behavior pattern of the scam, so when \nd\n is too large, overfitting occurs. At the same time, we conducted experiments on the context size \nk\n from 1-11, and the peak was reached when \nk\n=\n9\n. However, increasing \nwl\n did not make the indicators continue to rise, but decreased when \nw\nl\n=\n9\n, because when \nwl\n continued to increase, a large number of subsequent sampling nodes were repeated, resulting in the inability to accurately describe the scam behavior. For the number of walks per node \nr\n, the larger the \nr\n, the higher the indicators, because the larger the \nr\n, the more information is collected for the neuron to learn.\nFig. 5\nResults of (\na\n)\u2013(\nd\n) hyperparameters analysis\nEfficiency and scalability\nEfficiency\n To evaluate the detection efficiency and scalability of our proposed method, the times are averaged after running the program 100 times. We first compared the embedding time and detection time of each method on the graph we constructed, as shown in Fig\u00a0\n6\na. It can be seen from the figure that except for DeepWalk, which does not need to deal with node transition probability, the method proposed in this paper has the lowest embedding time and detection time. Combining with the comprehensive detection indicators show that our method has better detection efficiency.\nScalability\n In order to evaluate the scalability of the method, we conduct experiments on Erdos-Renyi(ER) random graphs using the tuned parameters, and the number of nodes is increased from 10\n2\n to 10\n5\n. Since ER graph nodes cannot set feature values, Therefore, we set the features we used in our method to 1, which does not affect the detection of scalability. The scalability is shown in Fig.\u00a0\n6\nb. As the number of nodes increases, both the sampling time and the sampling + optimization time increase linearly. So this shows that our method can be applied to large-scale graph detection such as Ethereum.\nFig. 6\nResults of efficiency and scalability"
    }
}