{
    "threat_intelligence": {
        "url": "https://www.technologyreview.com/2021/04/08/1021696/preparing-for-ai-enabled-cyberattacks/",
        "timestamp": "2020-01-01 00:00:00",
        "original_content": " \nMIT Technology Review Insights, in association with AI cybersecurity company Darktrace, surveyed more than 300 C-level executives, directors, and managers worldwide to understand how they\u2019re addressing the cyberthreats they\u2019re up against\u2014and how to use AI to help fight against them.\n \nAs it is, 60% of respondents report that human-driven responses to cyberattacks are failing to keep up with automated attacks, and as organizations gear up for a greater challenge, more sophisticated technologies are critical. In fact, an overwhelming majority of respondents\u201496%\u2014report they\u2019ve already begun to guard against AI-powered attacks, with some enabling AI defenses.\n \n\n\nOffensive AI cyberattacks are daunting, and the technology is fast and smart. Consider deepfakes, one type of weaponized AI tool, which are fabricated images or videos depicting scenes or people that were never present, or even existed.\n \nIn January 2020, the FBI warned that deepfake technology had already reached the point where artificial personas could be created that could pass biometric tests. At the rate that AI neural networks are evolving, an FBI official said at the time, national security could be undermined by high-definition, fake videos created to mimic public figures so that they appear to be saying whatever words the video creators put in their manipulated mouths. \n \n\n\nThis is just one example of the technology being used for nefarious purposes. AI could, at some point, conduct cyberattacks autonomously, disguising their operations and blending in with regular activity. The technology is out there for anyone to use, including threat actors.\n \nOffensive AI risks and developments in the cyberthreat landscape are redefining enterprise security, as humans already struggle to keep pace with advanced attacks. In particular, survey respondents reported that email and phishing attacks cause them the most angst, with nearly three quarters reporting that email threats are the most worrisome. That breaks down to 40% of respondents who report finding email and phishing attacks \u201cvery concerning,\u201d while 34% call them \u201csomewhat concerning.\u201d It\u2019s not surprising, as 94% of detected malware is still delivered by email. The traditional methods of stopping email-delivered threats rely on historical indicators\u2014namely, previously seen attacks\u2014as well as the ability of the recipient to spot the signs, both of which can be bypassed by sophisticated phishing incursions.\n \nWhen offensive AI is thrown into the mix, \u201cfake email\u201d will be almost indistinguishable from genuine communications from trusted contacts.\n \nHow attackers exploit the headlines\n \nThe coronavirus pandemic presented a lucrative opportunity for cybercriminals. Email attackers in particular followed a long-established pattern: take advantage of the headlines of the day\u2014along with the fear, uncertainty, greed, and curiosity they incite\u2014to lure victims in what has become known as \u201cfearware\u201d attacks. With employees working remotely, without the security protocols of the office in place, organizations saw successful phishing attempts skyrocket. Max Heinemeyer, director of threat hunting for Darktrace, notes that when the pandemic hit, his team saw an immediate evolution of phishing emails. \u201cWe saw a lot of emails saying things like, \u2018Click here to see which people in your area are infected,\u2019\u201d he says. When offices and universities started reopening last year, new scams emerged in lockstep, with emails offering \u201ccheap or free covid-19 cleaning programs and tests,\u201d says Heinemeyer.\n "
    }
}